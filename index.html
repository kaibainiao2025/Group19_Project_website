<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Gaussian-based Localized Anomaly Detection and Multi-class Classification of Industrial Machines using AudioResNet</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <div class="page">

    <header>
      <h1>Gaussian-based Localized Anomaly Detection and Multi-class Classification of Industrial Machines using AudioResNet</h1>

      <div class="authors">
        <p>
          Dhanush Dhana Shekar<sup>1</sup> &nbsp;
          Kiara Bermudez<sup>1</sup> &nbsp;
          Wenxin Guo<sup>1</sup> &nbsp;
          Avneesh Dubey<sup>1</sup> &nbsp;
        </p>
      </div>

      <nav class="top-nav">
        <a href="#abstract">Abstract</a>
        <a href="#dataset-example">Dataset Example</a>
        <a href="#dataset-summary">Dataset Summary</a>
        <a href="#masks">Evaluation of AST embeddings</a>
        <a href="#materials">Multi-Class Performance</a>
        <a href="#materials2">Anomaly Detection and Classification</a>
      </nav>
    </header>

    <main>

      <!-- ABSTRACT -->
      <section id="abstract">
        <h2>Abstract</h2>
        <p>
          Understanding machine sound patterns is crucial for industrial condition monitoring, 
          predictive maintenance, and safety. We design and train a custom AudioResNet, a 
          ResNet-inspired convolutional neural network that operates on Mel spectrograms for 
          machine-type classification and uses its intermediate features as custom embeddings. 
          These AudioResNet embeddings are evaluated with the classical machine learning classifiers 
          and compared directly with the available pre-trained AST embeddings in terms of classification 
          performance and representation quality. In comparison to the AST embeddings, the custom CNN 
          produced substantially lower-dimensional embeddings, with just 6 features being able to capture 
          90% of the variance. The AudioResNet is employed as a lightweight backbone for patch distribution 
          modelling (PaDiM), where a self-supervised Gaussian-metric-based learning algorithm is utilised 
          for anomaly detection and localisation in images. The Custom CNN-PaDIM ensemble model improves 
          anomaly-AUROC performance by +4.4 percentage points on average across seven machine classes in 
          comparison to the default ResNet18 PaDiM backbone, exemplifying the domain-specific optimisation
          in machine sound anomaly detection, which is paramount in areas of predictive maintenance of
          machinery and equipment, guiding various performance optimisation benefits.
        </p>
      </section>

      <!-- DATASET EXAMPLE -->
      <section id="dataset-example">
        <h2>Dataset Example</h2>

        <div class="figure">
          <img src="data_example.png" alt="Mel spectrogram examples">
          <p class="caption">
           Mel spectrogram examples for each of the seven machine types, with normal recordings 
            in the left column and anomalous recordings in the right column.
          </p>
        </div>
      </section>

      <!-- DATASET SUMMARY -->
      <section id="dataset-summary">
        <h2>Dataset Summary</h2>

        <div class="figure">
            <img src="dataset_summary_machine_type.png" alt="Dataset summary visualization1", style="width:33%; height:auto;">
            <img src="dataset_summary_anomaly.png" alt="Dataset summary visualization2", style="width:33%; height:auto;">
        </div>
      </section>
      <!-- Clustering metrics of AST embeddings-->
      <section id="masks">
        <h2>Clustering metrics of AST embeddings  </h2>

        <div class="figure">
          <img src="Evaluation_AST_embeddings.png" alt="Evaluation of AST embeddings", style="width:33%; height:auto;">
          <p class="caption">
            This table compares clustering models using Silhouette Score (cluster separation/compactness) 
            and Adjusted Rand Score (agreement with ground-truth labels). Overall, Agglomerative Clustering 
            and Bisecting K-Means perform best, with higher values on both metrics, while HDBSCAN shows the 
            weakest clustering quality among the methods.
          </p>
        </div>
      </section>

      <!-- MATERIALS -->
      <section id="materials">
        <h2>Multi-Class Performance</h2>

        <div class="figure-grid">
          <figure>
            <img src="AudioResNet_1.png" alt="AudioResNet Model Evaluation",style="width:10%; height:auto;">
            <img src="AudioResNet_2.png" alt="AudioResNet Model Evaluation",style="width:10%; height:auto;">
            <figcaption>The proposed AudioRestNet was able to achieve an accuracy of 99.1% on the DCASE 
              2023 Task 2 test set (7 vehicle sound classes, balanced) and a macro F1-score of 0.991 on 
              the test set, demonstrating excellent discriminative capabilities on the mel-spectrogram-
              transformed images of the audio samples using a lightweight architecture.</figcaption>
          </figure>

          <figure>
            <img src="Clustering_Performance_Comparison_Across_Models.png" alt="Clustering Performance Comparison Across Models">
            <figcaption>The custom embeddings generated showcased higher inter-cluster separability and 
              intra-cluster compactness when the same clustering techniques were employed on them. The 
              high Silhouette Scores and Adjusted Rand Indices validate this claim.</figcaption>
          </figure>

          <figure>
            <img src="Linear_probe_classification_accuracy.png" alt=" Linear probe classification accuracy using AudioResNet vs. pretrained AST embeddings">
            <figcaption>Differences are more dramatic in simpler models like Decision Trees and Naive 
              Bayes Classifiers, exemplifying the significantly cleaner, more Gaussian-like, and higher-margin
              class clusters in the embedding space. AST embeddings retain a lot of residual nonlinear overlaps,
              requiring stronger and complex classifiers like SVM to reach higher performances, while the 
              simplest Naive Bayes classifier outperforms the same with AudioResNet embeddings.</figcaption>
          </figure>
        </div>
      </section>

      <!-- MATERIALS -->
      <section id="materials2">
        <h2>Anomaly Detection and Classification</h2>

        <div class="figure-grid">
          <figure>
            <img src="AUROC.png" alt=" Per-class AUROC and F1 comparison between AudioResNet and ResNet-18">
            <figcaption>The custom backbone improves average image-level AUROC from 0.603 to 0.647 (+4.4 pp) 
              and average image-level F1-score from 0.498 to 0.531 (+3.3 pp), with significant gains of 9â€“12 
              percentage points on the most discriminative machine types (fan, bearing, gearbox). </figcaption>
          </figure>

          <figure>
            <img src="PaDiM heatmap.png" alt="PaDiM heatmap">
            <figcaption>PaDiM heatmap for the anomalous valve broadband noise (mechanical fault) flagged in red 
              (e.g., leakage, loose part, or vibration). The warmer regions in the heatmap indicate the anomalous 
              components.</figcaption>
          </figure>
        </div>
      </section>      
        <h3>Related Links</h3>
        <ul class="link-list">
          <li><a href="https://huggingface.co/datasets/renumics/dcase23-task2-enriched" target="_blank" rel="noopener">Dataset (repository)</a></li>
          <li><a href="https://colab.research.google.com/drive/1SnNso3j9Mk_vQ8j2_3prUSaqOjSigHzv" target="_blank" rel="noopener">Test Code</a></li>
          <li><a href="https://colab.research.google.com/drive/1DN1TGEgdb-NzEwbHqyMGgazDeL4D4jSU?usp=sharing" target="_blank" rel="noopener">Code</a></li>
        </ul>
      </section>
    </main>
  </div>
</body>
</html>













